<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Michael C Turchin" />

<meta name="date" content="2019-01-30" />

<title>bmass Introduction</title>






<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#header {
text-align: center;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; }  code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>

</head>

<body>




<h1 class="title toc-ignore">bmass Introduction</h1>
<h4 class="author"><em>Michael C Turchin</em></h4>
<h4 class="date"><em>2019-01-30</em></h4>



<p>This is an introductory example of how to run <code>bmass</code>. In this introductory example, we will:</p>
<ul>
<li>Download our example dataset</li>
<li>Quality control (QC) &amp; format our example dataset</li>
<li>Run <code>bmass</code></li>
<li>Access &amp; explore results</li>
</ul>
<div id="downloading-globallipids2013" class="section level2">
<h2>Downloading <code>GlobalLipids2013</code></h2>
<p>For this vigenette, we will be download and analyze the <code>GlobalLipids2013</code> dataset. To download the necessary files from <a href="http://csg.sph.umich.edu/willer/public/lipids2013/" class="uri">http://csg.sph.umich.edu/willer/public/lipids2013/</a>, run the following:</p>
<pre><code>mkdir my-directory/GlobalLipids2013
cd my-directory/GlobalLipids2013

wget http://csg.sph.umich.edu/abecasis/public/lipids2013/jointGwasMc_LDL.txt.gz
wget http://csg.sph.umich.edu/abecasis/public/lipids2013/jointGwasMc_HDL.txt.gz
wget http://csg.sph.umich.edu/abecasis/public/lipids2013/jointGwasMc_TG.txt.gz
wget http://csg.sph.umich.edu/abecasis/public/lipids2013/jointGwasMc_TC.txt.gz</code></pre>
</div>
<div id="formatting-qcing-our-dataset" class="section level2">
<h2>Formatting &amp; QC’ing our dataset</h2>
<p>To run bmass, it is recommended that at least a minimal level of QC is performed on the datasets of interest. Additionally, it is important that all the single nucleotide polymorphisms (SNPs) being analyzed are oriented to the same reference allele across all the phenotypes being included. This latter situation is emphasized so that the correct direction of effect is assigned to each phenotype for a given SNP (which is oriented based on reference allele).</p>
<p>Below is example bash code on how to reformat, conduct some basic QC, and orient the reference alleles on the <code>GlobalLipids2013</code> dataset. First, we will reformat our input datafiles to match the requirements for <code>bmass</code>. <code>bmass</code> expects input files to have the following columns: Chromosome, Basepair, Marker ID, Minor Allele Frequency (MAF), Reference Allele, Alternative Allele, Direction of Effect, p-Value, and Sample Size (N).</p>
<p>To create files that match these specifications, we will conduct the following: extract the columns that are needed, orient SNPs to the minor allele, and extract the direction of effect from the provided effect sizes.</p>
<pre><code>zcat jointGwasMc_HDL.txt.gz | sed 's/:/ /g' | sed 's/chr//g' | awk '{ print $1 &quot;\t&quot; $2 &quot;\t&quot; $5 &quot;\t&quot; $12 &quot;\t&quot; $6 &quot;\t&quot; $7 &quot;\t&quot; $8 &quot;\t&quot; $11 &quot;\t&quot; $10 }' | perl -lane '$F[4] = uc($F[4]); $F[5] = uc($F[5]); if ($F[6] &gt; 0) { $F[6] = &quot;+&quot;; } elsif ($F[6] &lt; 0) { $F[6] = &quot;-&quot;; } else { $F[6] = 0; } print join(&quot;\t&quot;, @F);' | grep -v SNP_hg18 | gzip &gt; jointGwasMc_HDL.formatted.txt.gz 

zcat jointGwasMc_LDL.txt.gz | sed 's/:/ /g' | sed 's/chr//g' | awk '{ print $1 &quot;\t&quot; $2 &quot;\t&quot; $5 &quot;\t&quot; $12 &quot;\t&quot; $6 &quot;\t&quot; $7 &quot;\t&quot; $8 &quot;\t&quot; $11 &quot;\t&quot; $10 }' | perl -lane '$F[4] = uc($F[4]); $F[5] = uc($F[5]); if ($F[6] &gt; 0) { $F[6] = &quot;+&quot;; } elsif ($F[6] &lt; 0) { $F[6] = &quot;-&quot;; } else { $F[6] = 0; } print join(&quot;\t&quot;, @F);' | grep -v SNP_hg18 | gzip &gt; jointGwasMc_LDL.formatted.txt.gz 

zcat jointGwasMc_TG.txt.gz | sed 's/:/ /g' | sed 's/chr//g' | awk '{ print $1 &quot;\t&quot; $2 &quot;\t&quot; $5 &quot;\t&quot; $12 &quot;\t&quot; $6 &quot;\t&quot; $7 &quot;\t&quot; $8 &quot;\t&quot; $11 &quot;\t&quot; $10 }' | perl -lane '$F[4] = uc($F[4]); $F[5] = uc($F[5]); if ($F[6] &gt; 0) { $F[6] = &quot;+&quot;; } elsif ($F[6] &lt; 0) { $F[6] = &quot;-&quot;; } else { $F[6] = 0; } print join(&quot;\t&quot;, @F);' | grep -v SNP_hg18 | gzip &gt; jointGwasMc_TG.formatted.txt.gz 

zcat jointGwasMc_TC.txt.gz | sed 's/:/ /g' | sed 's/chr//g' | awk '{ print $1 &quot;\t&quot; $2 &quot;\t&quot; $5 &quot;\t&quot; $12 &quot;\t&quot; $6 &quot;\t&quot; $7 &quot;\t&quot; $8 &quot;\t&quot; $11 &quot;\t&quot; $10 }' | perl -lane '$F[4] = uc($F[4]); $F[5] = uc($F[5]); if ($F[6] &gt; 0) { $F[6] = &quot;+&quot;; } elsif ($F[6] &lt; 0) { $F[6] = &quot;-&quot;; } else { $F[6] = 0; } print join(&quot;\t&quot;, @F);' | grep -v SNP_hg18 | gzip &gt; jointGwasMc_TC.formatted.txt.gz </code></pre>
<p>Next, we will conduct some basic level QC steps. These steps include: remove duplicate entries of SNPs, remove SNPs that do not have entries in every field, do not have MAF information, that are fixed (MAF = 0), are rare (MAF &lt; .01), have sample sample sizes &lt; 50000, and have effect sizes of 0 (ie direction of effect is indeterminable). We will also orient each SNP/phenotype file to its respective minor allele.</p>
<pre><code>join &lt;(zcat jointGwasMc_HDL.formatted.txt.gz | awk '{ print $1 &quot;_&quot; $2 }' | grep -v hg18 | sort | uniq -u) &lt;(zcat jointGwasMc_HDL.formatted.txt.gz | grep -v hg | grep -v ^rs | grep -v NA | perl -lane 'if ($F[3] &gt; .5) { ($F[4], $F[5]) = ($F[5], $F[4]); if ($F[6] eq &quot;+&quot;) { $F[6] = &quot;-&quot;; } elsif ($F[6] eq &quot;-&quot;) { $F[6] = &quot;+&quot;; } else { $F[6] = 0; } $F[3] = 1 - $F[3]; } if ($F[6] ne &quot;0&quot;) { if ($F[3] &gt; .01) { if ($F[8] &gt;= 50000) { print join(&quot;\t&quot;, @F); } } }' | awk '{ print $1 &quot;_&quot; $2 &quot;\t&quot; $0 }' | sort -k 1,1) | perl -lane 'print join(&quot;\t&quot;, @F[1..$#F]);' | cat &lt;(echo -e &quot;Chr\tBP\tMarker\tMAF\tA1\tA2\tDirection\tpValue\tN&quot;) - | gzip &gt; jointGwasMc_HDL.formatted.QCed.txt.gz 

join &lt;(zcat jointGwasMc_LDL.formatted.txt.gz | awk '{ print $1 &quot;_&quot; $2 }' | grep -v hg18 | sort | uniq -u) &lt;(zcat jointGwasMc_LDL.formatted.txt.gz | grep -v hg | grep -v ^rs | grep -v NA | perl -lane 'if ($F[3] &gt; .5) { ($F[4], $F[5]) = ($F[5], $F[4]); if ($F[6] eq &quot;+&quot;) { $F[6] = &quot;-&quot;; } elsif ($F[6] eq &quot;-&quot;) { $F[6] = &quot;+&quot;; } else { $F[6] = 0; } $F[3] = 1 - $F[3]; } if ($F[6] ne &quot;0&quot;) { if ($F[3] &gt; .01) { if ($F[8] &gt;= 50000) { print join(&quot;\t&quot;, @F); } } }' | awk '{ print $1 &quot;_&quot; $2 &quot;\t&quot; $0 }' | sort -k 1,1) | perl -lane 'print join(&quot;\t&quot;, @F[1..$#F]);' | gzip &gt; jointGwasMc_LDL.formatted.QCed.txt.gz 

join &lt;(zcat jointGwasMc_TG.formatted.txt.gz | awk '{ print $1 &quot;_&quot; $2 }' | grep -v hg18 | sort | uniq -u) &lt;(zcat jointGwasMc_TG.formatted.txt.gz | grep -v hg | grep -v ^rs | grep -v NA | perl -lane 'if ($F[3] &gt; .5) { ($F[4], $F[5]) = ($F[5], $F[4]); if ($F[6] eq &quot;+&quot;) { $F[6] = &quot;-&quot;; } elsif ($F[6] eq &quot;-&quot;) { $F[6] = &quot;+&quot;; } else { $F[6] = 0; } $F[3] = 1 - $F[3]; } if ($F[6] ne &quot;0&quot;) { if ($F[3] &gt; .01) { if ($F[8] &gt;= 50000) { print join(&quot;\t&quot;, @F); } } }' | awk '{ print $1 &quot;_&quot; $2 &quot;\t&quot; $0 }' | sort -k 1,1) | perl -lane 'print join(&quot;\t&quot;, @F[1..$#F]);' | gzip &gt; jointGwasMc_TG.formatted.QCed.txt.gz 

join &lt;(zcat jointGwasMc_TC.formatted.txt.gz | awk '{ print $1 &quot;_&quot; $2 }' | grep -v hg18 | sort | uniq -u) &lt;(zcat jointGwasMc_TC.formatted.txt.gz | grep -v hg | grep -v ^rs | grep -v NA | perl -lane 'if ($F[3] &gt; .5) { ($F[4], $F[5]) = ($F[5], $F[4]); if ($F[6] eq &quot;+&quot;) { $F[6] = &quot;-&quot;; } elsif ($F[6] eq &quot;-&quot;) { $F[6] = &quot;+&quot;; } else { $F[6] = 0; } $F[3] = 1 - $F[3]; } if ($F[6] ne &quot;0&quot;) { if ($F[3] &gt; .01) { if ($F[8] &gt;= 50000) { print join(&quot;\t&quot;, @F); } } }' | awk '{ print $1 &quot;_&quot; $2 &quot;\t&quot; $0 }' | sort -k 1,1) | perl -lane 'print join(&quot;\t&quot;, @F[1..$#F]);' | gzip &gt; jointGwasMc_TC.formatted.QCed.txt.gz </code></pre>
<p>Lastly, we will orient all phenotype files to the HDL minor allele:</p>
<pre><code>join &lt;(zcat jointGwasMc_HDL.formatted.QCed.txt.gz | awk '{ print $1 &quot;_&quot; $2 &quot;\t&quot; $5 }' | sort -k 1,1) &lt;(zcat jointGwasMc_LDL.formatted.QCed.txt.gz | awk '{ print $1 &quot;_&quot; $2 &quot;\t&quot; $0 }' | sort -k 1,1) | perl -lane 'if ($F[1] eq $F[7]) { ($F[6], $F[7]) = ($F[7], $F[6]); if ($F[8] eq &quot;-&quot;) { $F[8] = &quot;+&quot;; } elsif ($F[8] eq &quot;+&quot;) { $F[8] = &quot;-&quot;; } else { print STDERR &quot;Error1 -- direction of effect allele matching&quot;; } } print join(&quot;\t&quot;, @F[2..$#F]);' | cat &lt;(echo -e &quot;Chr\tBP\tMarker\tMAF\tA1\tA2\tDirection\tpValue\tN&quot;) - | gzip &gt; jointGwasMc_LDL.formatted.QCed.HDLMatch.txt.gz

join &lt;(zcat jointGwasMc_HDL.formatted.QCed.txt.gz | awk '{ print $1 &quot;_&quot; $2 &quot;\t&quot; $5 }' | sort -k 1,1) &lt;(zcat jointGwasMc_TG.formatted.QCed.txt.gz | awk '{ print $1 &quot;_&quot; $2 &quot;\t&quot; $0 }' | sort -k 1,1) | perl -lane 'if ($F[1] eq $F[7]) { ($F[6], $F[7]) = ($F[7], $F[6]); if ($F[8] eq &quot;-&quot;) { $F[8] = &quot;+&quot;; } elsif ($F[8] eq &quot;+&quot;) { $F[8] = &quot;-&quot;; } else { print STDERR &quot;Error1 -- direction of effect allele matching&quot;; } } print join(&quot;\t&quot;, @F[2..$#F]);' | cat &lt;(echo -e &quot;Chr\tBP\tMarker\tMAF\tA1\tA2\tDirection\tpValue\tN&quot;) - | gzip &gt; jointGwasMc_TG.formatted.QCed.HDLMatch.txt.gz

join &lt;(zcat jointGwasMc_HDL.formatted.QCed.txt.gz | awk '{ print $1 &quot;_&quot; $2 &quot;\t&quot; $5 }' | sort -k 1,1) &lt;(zcat jointGwasMc_TC.formatted.QCed.txt.gz | awk '{ print $1 &quot;_&quot; $2 &quot;\t&quot; $0 }' | sort -k 1,1) | perl -lane 'if ($F[1] eq $F[7]) { ($F[6], $F[7]) = ($F[7], $F[6]); if ($F[8] eq &quot;-&quot;) { $F[8] = &quot;+&quot;; } elsif ($F[8] eq &quot;+&quot;) { $F[8] = &quot;-&quot;; } else { print STDERR &quot;Error1 -- direction of effect allele matching&quot;; } } print join(&quot;\t&quot;, @F[2..$#F]);' | cat &lt;(echo -e &quot;Chr\tBP\tMarker\tMAF\tA1\tA2\tDirection\tpValue\tN&quot;) - | gzip &gt; jointGwasMc_TC.formatted.QCed.HDLMatch.txt.gz</code></pre>
</div>
<div id="running-bmass" class="section level2">
<h2>Running <code>bmass</code></h2>
<p>Now with our four <code>GlobalLipids2013</code> files properly formatted and QCed, we are able to run <code>bmass</code>. To do so, we will also need the list of published univariate GWAS SNPs from the <code>GlobalLipids2013</code> publication (presented as two columns per SNP, chromosome and basepair position) – these have been provided in the <code>data</code> subdirectory (<code>GlobalLipids2013.GWASsnps.txt</code>). To run <code>bmass</code> with our prepared input datafiles and our list of univariate GWAS SNPs, we run the following R code:</p>
<pre><code>library(&quot;bmass&quot;);
library(&quot;devtools&quot;); devtools::load_all(&quot;/home/mturchin20/project/Lab_Stuff/StephensLab/bmass&quot;);
HDL &lt;- read.table(&quot;jointGwasMc_HDL.formatted.QCed.txt.gz&quot;, header=T);
LDL &lt;- read.table(&quot;jointGwasMc_LDL.formatted.QCed.HDLMatch.txt.gz&quot;, header=T);
TG &lt;- read.table(&quot;jointGwasMc_TG.formatted.QCed.HDLMatch.txt.gz&quot;, header=T); 
TC &lt;- read.table(&quot;jointGwasMc_TC.formatted.QCed.HDLMatch.txt.gz&quot;, header=T);
GWASsnps &lt;- read.table(&quot;../data/GlobalLipids2013.GWASsnps.txt&quot;, header=T);
Phenotypes &lt;- c(&quot;HDL&quot;, &quot;LDL&quot;, &quot;TG&quot;, &quot;TC&quot;);
bmassResults &lt;- bmass(Phenotypes, GWASsnps);</code></pre>
<p>Note that to run <code>bmass</code> we supply a vector of phenotype names that also correspond to the variable names referencing each phenotype’s respective data file. Also note that you will see a warning that one or more of the <code>GlobalLipids2013</code> datafiles contains p-values smaller than the threshold at which R can handle converting them into logarthmic scale – this is to be expected.</p>
</div>
<div id="accessing-exploring-results" class="section level2">
<h2>Accessing &amp; exploring results</h2>
<p><code>bmass</code> returns a list containing multiple areas of information, including separate sublists pertaining to the previous univariate GWAS SNPs used for training the multivariate model priors and the new multivariate SNPs (if any) bmass has idenfitifed as significant. Run <code>summary(bmassResults)</code> and you should see the following:</p>
<pre><code>&gt; summary(bmassResults)
                      Length Class  Mode     
MarginalSNPs             3   -none- list     
PreviousSNPs             4   -none- list     
NewSNPs                  3   -none- list     
LogFile                 20   -none- character
ZScoresCorMatrix        16   -none- numeric  
Models                 324   -none- numeric  
ModelPriors           1134   -none- numeric  
GWASlogBFMinThreshold    1   -none- numeric  </code></pre>
<p>We will touch on all the above outputs.</p>
<div id="newsnps" class="section level4">
<h4>NewSNPs</h4>
<p>The <code>NewSNPs</code> sublist contains information pertaining to the new significant multivariate associations found by <code>bmass</code>, if any were identified. Running <code>summary(bmassResults$NewSNPs)</code> you should see the following:</p>
<pre><code>&gt; summary(bmassResults$NewSNPs)
           Length Class      Mode   
SNPs         30   data.frame list   
logBFs     5427   -none-     numeric
Posteriors 5427   -none-     numeric</code></pre>
<p><code>bmassResults$NewSNPs$SNPs</code> contains the ‘main’ <code>bmass</code> output of interest – the list of new multivariate associations found by <code>bmass</code> and those SNPs’ related information. The format of this output appears as follows:</p>
<pre><code>&gt; head(bmassResults$NewSNPs$SNPs, n=3)
              ChrBP Chr        BP    Marker    MAF A1 HDL_A2 HDL_Direction
1704   10_101902054  10 101902054 rs2862954 0.4631  C      T             +
72106    10_5839619  10   5839619 rs2275774 0.1781  G      A             +
118903 11_109521729  11 109521729  rs661171 0.2876  T      G             +
       HDL_pValue  HDL_N HDL_ZScore LDL_Direction LDL_pValue    LDL_N
1704    1.287e-06 186893   4.841751             +  5.875e-01 172821.0
72106   7.601e-07 179144   4.945343             -  7.773e-05 165198.0
118903  1.705e-06 186946   4.785573             +  1.653e-02 172877.9
       LDL_ZScore TG_Direction TG_pValue     TG_N TG_ZScore TC_Direction
1704    0.5424624            +  0.013930 177587.1  2.459063            +
72106  -3.9512933            -  0.001035 169853.0 -3.280836            -
118903  2.3969983            -  0.155800 177645.0 -1.419340            +
       TC_pValue   TC_N TC_ZScore GWASannot   mvstat mvstat_log10pVal  unistat
1704   2.526e-04 187083  3.659609         0 48.70946         9.173067 23.44255
72106  1.911e-02 179333 -2.343378         0 38.26288         7.004804 24.45642
118903 1.785e-05 187131  4.290215         0 37.84098         6.917765 22.90171
       unistat_log10pVal     Nmin logBFWeightedAvg
1704            5.890421 172821.0         7.068306
72106           6.119129 165198.0         5.447201
118903          5.768276 172877.9         5.438490</code></pre>
<p><code>NewSNPs$logBFs</code> contains the log10 Bayes Factor (BF) for each multivariate model tested (in the form of a Model x SNP matrix, with the first columns of the matrix describing each model). <code>NewSNPs$Posteriors</code> is a similar matrix, just with each matrix entry representing the posterior probability for each model/SNP combination instead of the log10 BF.</p>
<pre><code>&gt; dim(bmassResults$NewSNPs$logBFs)
[1] 81 67
&gt; bmassResults$NewSNPs$logBFs[1:5,1:10]
     HDL LDL TG TC 10_101902054   10_5839619 11_109521729   11_13313759
[1,]   0   0  0  0     0.000000    0.0000000    0.0000000    0.00000000
[2,]   1   0  0  0  -233.831047 -235.0781367 -234.6670299 -234.15472067
[3,]   2   0  0  0     0.000000    0.0000000    0.0000000    0.00000000
[4,]   0   1  0  0     0.165855    0.3172489   -0.1100418    0.06393596
[5,]   1   1  0  0   -64.774919  -66.2959645  -69.2388829  -69.93309528
       11_45696596   11_47251202
[1,]    0.00000000    0.00000000
[2,] -231.68478695 -219.10321932
[3,]    0.00000000    0.00000000
[4,]   -0.04838241    0.04997886
[5,]  -65.59917325  -45.04269241</code></pre>
</div>
<div id="previoussnps" class="section level4">
<h4>PreviousSNPs</h4>
<p><code>PreviousSNPs</code> contains similar information as <code>NewSNPs</code> does, but pertaining to the set of previous univariate GWAS significant SNPs used to train the multivariate model priors and set the empirical significance threshold for weighted average BF. Running <code>summary(bmassResults$PreviousSNPs)</code> you see:</p>
<pre><code>&gt; summary(bmassResults$PreviousSNPs)
             Length Class      Mode   
logBFs       12069  -none-     numeric
SNPs            30  data.frame list   
DontPassSNPs    30  data.frame list   
Posteriors   12069  -none-     numeric</code></pre>
<p><code>PreviousSNPs$SNPs</code>, <code>PreviousSNPs$logBFs</code>, and <code>PreviousSNPs$Posteriors</code> all match the descriptions as above with <code>NewSNPs</code>. However <code>PreviousSNPs$DontPassSNPs</code> refers to any GWAS SNPs which are included in the final publicaiton list but which do meet the original study’s univariate GWAS p-value threshold based on the dataset released. This can for instance occur when a final GWAS SNP list is produced from combining a discovery dataset with a replication dataset, and the former data is the only part of the study publicly released. Therefore <code>bmass</code> keeps track of these SNPs so as not to call them a completely novel multivariate SNP, but also to not use them to train the multivariate model priors since they do not technically reach univariate GWAS significance based on the dataset provided alone.</p>
<p>The format of <code>DontPassSNPs</code> is the same seen in <code>NewSNPs$SNPs</code> and <code>PreviousSNPs$SNPs</code>.</p>
</div>
<div id="marginalsnps" class="section level4">
<h4>MarginalSNPs</h4>
<p><code>MarginalSNPs</code> contains the same information as <code>NewSNPs</code> and <code>PreviousSNPs</code>, but pertaining to the set of marginally significant SNPs extracted from the intermediate <code>MergedDataSources</code> dataset (a data.frame that contains all the input phenotype files combined) based on the <code>SNPMarginalUnivariateThreshold</code> and <code>SNPMarginalMultivariateThreshold</code> values (default of 1e-6 for each). <code>summary(bmassResults$MarginalSNPs)</code> returns:</p>
<pre><code>&gt; summary(bmassResults$MarginalSNPs)
           Length Class      Mode   
SNPs          30  data.frame list   
logBFs     20493  -none-     numeric
Posteriors 20493  -none-     numeric</code></pre>
<p><code>MarginalSNPs$SNPs</code>, <code>MarginalSNPs$logBFs</code>, and <code>MarginalSNPs$Posteriors</code> are all as described above.</p>
</div>
<div id="zscorescormatrix" class="section level4">
<h4>ZScoresCorMatrix</h4>
<p>This is the phenotype correlation matrix (V_0 hat in <code>Detailed Methods (Global Lipids Analysis)</code> of Stephens 2013 PLoS ONE) derived from extracting all the ‘null’ SNPs (abs(ZScore) &lt; 2 for every phenotype) in the dataset.</p>
<pre><code>&gt; bmassResults$ZScoresCorMatrix
           HDL_ZScore LDL_ZScore  TG_ZScore TC_ZScore
HDL_ZScore  1.0000000 -0.0872789 -0.3655508 0.1523894
LDL_ZScore -0.0872789  1.0000000  0.1607208 0.8223175
TG_ZScore  -0.3655508  0.1607208  1.0000000 0.2892982
TC_ZScore   0.1523894  0.8223175  0.2892982 1.0000000</code></pre>
</div>
<div id="models" class="section level4">
<h4>Models</h4>
<p>This is a matrix displaying all the model combinations possible given the set of d input phenotypes and 3 model categories of directly associated (1), indirectly associated (2), and unassociated (0). The total number of models displayed should be 3^d.</p>
<pre><code>&gt; dim(bmassResults$Models)
[1] 81  4
&gt; head(bmassResults$Models)
     [,1] [,2] [,3] [,4]
[1,]    0    0    0    0
[2,]    1    0    0    0
[3,]    2    0    0    0
[4,]    0    1    0    0
[5,]    1    1    0    0
[6,]    2    1    0    0</code></pre>
</div>
<div id="modelpriors" class="section level4">
<h4>ModelPriors</h4>
<p>This is set of priors determined for each multivariate model using the previous univariate GWAS SNPs and an EM algorithm setup (see eq. 36 in Stephens 2013). Note that for any model which does not contain at least one phenotype in the directly associated category, the prior was automatically set to 0 (aside from the global null model of all phenotypes set to unassociated).</p>
<pre><code>&gt; length(bmassResults$ModelPriors)
[1] 1134
dim?
head?
&gt; head(cbind(bmassResults$Models, matrix(bmassResults$ModelPriors, nrow=81, byrow=FALSE)))
     [,1] [,2] [,3] [,4]          [,5]          [,6]          [,7]
[1,]    0    0    0    0  0.000000e+00  0.000000e+00  0.000000e+00
[2,]    1    0    0    0  0.000000e+00 1.524507e-270 1.032154e-247
[3,]    2    0    0    0  0.000000e+00  0.000000e+00  0.000000e+00
[4,]    0    1    0    0  0.000000e+00  0.000000e+00  0.000000e+00
[5,]    1    1    0    0 8.712578e-276 8.168092e-194 9.142506e-140
[6,]    2    1    0    0  0.000000e+00  0.000000e+00  0.000000e+00</code></pre>
</div>
<div id="gwaslogbfminthreshold" class="section level4">
<h4>GWASlogBFMinThreshold</h4>
<p>This is the empirical weighted average BF threshold (BFavg) used to determine whether any new SNPs are ‘multivariate significant’. As described in Stephens 2013, each SNP has a single summary metric combining all the information across each multivariate model tested; this summary metric is the weighted average of each model’s BF, where weights are determined from the previous univariate GWAS SNPs (eq. 8 in Stephens 2013). This summary metric is also calculated for the previous unviariate GWAS SNPs themselves, and the smallest BFavg among them becomes the threshold above which new SNPs are considered multivariate significant.</p>
<pre><code>&gt; bmassResults$GWASlogBFMinThreshold
[1] 4.289906</code></pre>
<p>So every new multivariate SNP <code>bmass</code> identifies in this <code>GlobalLipids2013</code> analysis has a BFavg value &gt;= 4.289906 (and is also more than a 1Mb window away from a previous univariate GWAS SNP).</p>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
